name: tripy_ai

services:
  # 1. FastAPI 서버 (딥러닝 모델 + 로직)
  tripy_fastapi:
    build: .
    image: tripy-fastapi
    container_name: fastapi
    ports:
      - "8000:8000"
    networks:
      - tripyserver
    volumes:
      # 소스코드
      # - .:/app  # 배포 시에는 이미지 안에 코드가 포함되어야 함.
      # [내 컴퓨터의 모델 폴더 경로] : [컨테이너 내부 경로]
      - ./model:/app/model
    env_file:
      - .env
    environment:
      - REDIS_HOST=tripy_redis
      - OLLAMA_HOST=http://ollama:11434 # Ollama 컨테이너 주소
      - CHROMA_HOST=chroma # Chroma 컨테이너 주소
      - CHROMA_PORT=8000

  # 2. Ollama (LLM 실행 엔진)
  tripy_ollama:
    image: ollama/ollama:latest
    container_name: ollama
    networks:
      - tripyserver
    ports:
      - "11434:11434" # 외부에서 테스트할 때 필요
    volumes:
      - ollama_storage:/root/.ollama # 모델 다운로드 데이터 보존 (중요!)

  # 3. ChromaDB (벡터 데이터베이스)
  tripy_chroma:
    image: chromadb/chroma:latest
    container_name: chroma
    networks:
      - tripyserver
    ports:
      - "8001:8000" # 8000은 FastAPI가 쓰니까 충돌 방지로 8001 매핑
    volumes:
      - chroma_storage:/chroma/chroma # 벡터 데이터 보존 (중요!)

networks:
  tripyserver:
    external: true

volumes:
  ollama_storage:
  chroma_storage:
